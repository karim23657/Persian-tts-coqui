{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!python --version\n","!nvidia-smi\n","!sudo apt-get -y install espeak-ng\n","!sudo apt-get install python3.9-distutils\n","!sudo apt-get install python3.9\n","!pip -q install uv\n","!uv pip -q install virtualenv --system\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!virtualenv -p python3.9 my_env\n","!source my_env/bin/activate; pip list\n","!source my_env/bin/activate; pip -q install uv\n","!source my_env/bin/activate; uv pip -q install coqui-tts==0.25.1 "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!mkdir train_output\n","!mkdir train_output/kagg"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!wget https://raw.githubusercontent.com/coqui-ai/TTS/main/TTS/bin/collect_env_info.py\n","!source my_env/bin/activate; python collect_env_info.py"]},{"cell_type":"markdown","metadata":{},"source":["Ø¯Ø± Ú©Ø¯ Ø²ÛŒØ± Ù…Ø³ÛŒØ± Ø¯ÛŒØªØ§Ø³Øª Ùˆ \n","sample_rate ÙØ§ÛŒÙ„ Ù‡Ø§ÛŒ ØµÙˆØªÛŒ ØªØ§Ù† Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["code='''import os\n","\n","from trainer import Trainer, TrainerArgs\n","\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig , CharactersConfig\n","from TTS.config.shared_configs import BaseAudioConfig\n","from TTS.tts.configs.vits_config import VitsConfig\n","from TTS.tts.datasets import load_tts_samples\n","from TTS.tts.models.vits import Vits, VitsAudioConfig\n","from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","from TTS.utils.audio import AudioProcessor\n","from TTS.utils.downloaders import download_thorsten_de\n","\n","output_path = os.path.dirname(os.path.abspath(__file__))\n","dataset_config = BaseDatasetConfig(\n","    formatter=\"mozilla\", meta_file_train=\"metadata.csv\", path=\"Path to your dataset\" \n",")\n","\n","\n","\n","audio_config = BaseAudioConfig(\n","    sample_rate=22050,\n","    do_trim_silence=False,\n","    resample=False,\n","    mel_fmin=0,\n","    mel_fmax=None \n",")\n","character_config=CharactersConfig(\n","  characters='Ø¡Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ù„Ù…Ù†Ù‡ÙˆÙŠÙÙ¾Ú†Ú˜Ú©Ú¯ÛŒØ¢Ø£Ø¤Ø¥Ø¦Ù‹ÙÙÙ‘',\n","  punctuations='!(),-.:;? Ì ØŒØ›ØŸâ€Œ<>',\n","  phonemes='ËˆËŒËË‘pbtdÊˆÉ–cÉŸkÉ¡qÉ¢Ê”É´Å‹É²É³nÉ±mÊ™rÊ€â±±É¾É½É¸Î²fvÎ¸Ã°szÊƒÊ’Ê‚ÊÃ§ÊxÉ£Ï‡ÊÄ§Ê•hÉ¦É¬É®Ê‹É¹É»jÉ°lÉ­ÊÊŸaegiouwyÉªÊŠÌ©Ã¦É‘É”É™ÉšÉ›ÉÉ¨ÌƒÊ‰ÊŒÊ0123456789\"#$%*+/=ABCDEFGHIJKLMNOPRSTUVWXYZ[]^_{}',\n","  pad=\"<PAD>\",\n","  eos=\"<EOS>\",\n","  bos=\"<BOS>\",\n","  blank=\"<BLNK>\",\n","  characters_class=\"TTS.tts.utils.text.characters.IPAPhonemes\",\n","  )\n","config = VitsConfig(\n","    audio=audio_config,\n","    run_name=\"vits_fa_male\",\n","    batch_size=16,\n","    eval_batch_size=8,\n","    batch_group_size=5,\n","    num_loader_workers=0,\n","    num_eval_loader_workers=2,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=1000,\n","    save_step=1000,\n","    text_cleaner=\"basic_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"fa\",\n","    characters=character_config,\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    compute_input_seq_cache=True,\n","    print_step=250,\n","    print_eval=False,\n","    mixed_precision=False,\n","    test_sentences=[\n","        [\"Ø³Ù„Ø·Ø§Ù† Ù…Ø­Ù…ÙˆØ¯ Ø¯Ø± Ø²Ù…Ø³ØªØ§Ù†ÛŒ Ø³Ø®Øª Ø¨Ù‡ Ø·Ù„Ø®Ú© Ú¯ÙØª \"],\n","        [\"Ú©Ø§Ø±Ù„ Ùˆ Ù„Ø±Ù„ Ú©Ø§Ø±Ù‡Ø§ Ø±Ùˆ Ø±Ù„Ù‡ Ú©Ø±Ø¯Ù† \"],\n","        [\"Ù…Ø±Ø¯ÛŒ Ù†Ø²Ø¯ Ø¨Ù‚Ø§Ù„ÛŒ Ø¢Ù…Ø¯ Ùˆ Ú¯ÙØª Ù¾ÛŒØ§Ø² Ù‡Ù… Ø¯Ù‡ ØªØ§ Ø¯Ù‡Ø§Ù† Ø¨Ø¯Ø§Ù† Ø®Ùˆ Ø´Ø¨ÙˆÛŒ Ø³Ø§Ø²Ù….\"],\n","        [\"Ø³Ù‡ Ø³ÛŒØ± Ø³Ø±Ø´ÛŒØ± Ø³Ù‡ Ø´ÛŒØ´Ù‡ Ø´ÛŒØ±! \"],\n","        [\"Ø§Ø² Ù…Ø§Ù„ Ø®ÙˆØ¯ Ù¾Ø§Ø±Ù‡ Ø§ÛŒ Ú¯ÙˆØ´Øª Ø¨Ø³ØªØ§Ù† Ùˆ Ø²ÛŒØ±Ù‡ Ø¨Ø§ÛŒÛŒ Ù…Ø¹Ø·Ù‘Ø± Ø¨Ø³Ø§Ø²\"],\n","        [\"Ù„ÙˆØ±Ù„ Ø±ÙˆÛŒ Ø±ÛŒÙ„ Ø±Ø§Ù‡ Ù…ÛŒØ±ÙØª \"],\n","        [\"ÛŒÚ©ÛŒ Ø§Ø³Ø¨ÛŒ Ø¨Ù‡ Ø¹Ø§Ø±ÛŒØª Ø®ÙˆØ§Ø³Øª\"]\n","    ],\n","    output_path=output_path,\n","    datasets=[dataset_config],\n",")\n","\n","# INITIALIZE THE AUDIO PROCESSOR\n","# Audio processor is used for feature extraction and audio I/O.\n","# It mainly serves to the dataloader and the training loggers.\n","ap = AudioProcessor.init_from_config(config)\n","\n","# INITIALIZE THE TOKENIZER\n","# Tokenizer is used to convert text to sequences of token IDs.\n","# config is updated with the default characters if not defined in the config.\n","tokenizer, config = TTSTokenizer.init_from_config(config)\n","\n","# LOAD DATA SAMPLES\n","# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n","# You can define your custom sample loader returning the list of samples.\n","# Or define your custom formatter and pass it to the `load_tts_samples`.\n","# Check `TTS.tts.datasets.load_tts_samples` for more details.\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")\n","\n","# init model\n","model = Vits(config, ap, tokenizer, speaker_manager=None)\n","\n","# init the trainer and ğŸš€\n","trainer = Trainer(\n","    TrainerArgs(),\n","    config,\n","    output_path,\n","    model=model,\n","    train_samples=train_samples,\n","    eval_samples=eval_samples,\n",")\n","trainer.fit()'''\n","f=open(\"train_output/train_vits.py\",\"w\",encoding=\"utf-8\")\n","\n","f.write(code)\n","\n","f.close()"]},{"cell_type":"markdown","metadata":{},"source":["Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ù…ÛŒ Ø®ÙˆØ§Ù‡ÛŒØ¯ Ø±ÙˆÛŒ Ø¢Ù† finetune \n","Ú©Ù†ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!wget \"https://huggingface.co/Kamtera/persian-tts-male1-vits/resolve/main/checkpoint_166000.pth?download=true\" \\\n","    -O train_output/kagg/checkpoint_166000.pth\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!ls -ul 'train_output'\n","!ls -ul /kaggle/working/"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!source my_env/bin/activate; PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:512\" python \"train_output/train_vits.py\" \\\n","--restore_path \"train_output/kagg/checkpoint_166000.pth\" \\\n","--coqpit.run_name \"vits-male-finetune\" "]}],"metadata":{"kaggle":{"accelerator":"gpu","isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
					
