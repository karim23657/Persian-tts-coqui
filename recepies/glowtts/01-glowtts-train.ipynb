{"cells":[{"cell_type":"markdown","metadata":{"id":"XwRnOU3TTcSS"},"source":["# Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxgDu46oTbj7","trusted":true},"outputs":[],"source":["!pip install -q TTS\n","!sudo apt-get -y install espeak-ng"]},{"cell_type":"markdown","metadata":{"id":"D_PWn1BnUYXr"},"source":["## Insert Dataset"]},{"cell_type":"markdown","metadata":{},"source":["You can use kaggle api to download dataset:\n","https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-famale"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-23T13:21:19.931307Z","iopub.status.busy":"2022-12-23T13:21:19.930904Z","iopub.status.idle":"2022-12-23T13:21:20.876866Z","shell.execute_reply":"2022-12-23T13:21:20.875514Z","shell.execute_reply.started":"2022-12-23T13:21:19.931274Z"},"id":"UzjI324SYnSI","trusted":true},"outputs":[],"source":["!mkdir train_output"]},{"cell_type":"markdown","metadata":{},"source":["You should set your own dataset path in bellow cell like this:\n","\n","exp. : my dataset path is `/contents/persian-tts-dataset-famale` and these are files under folder:\n","```\n","/contents/persian-tts-dataset-famale\n","|-- wavs\n","|   |-- 1.wav\n","|   |-- 2.wav\n","|   |-- 3.wav\n","|   |-- ...\n","|\n","|\n","|-- metadata.csv\n","```\n","So this part of code should be (lines 26-28 in train_glowtts.py or bellow cell) like this:\n","```\n","dataset_config = BaseDatasetConfig(\n","    formatter=\"mozilla\", meta_file_train=\"metadata.csv\", path=\"/contents/persian-tts-dataset-famale\" \n",")\n","```\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-12-23T14:09:14.192412Z","iopub.status.busy":"2022-12-23T14:09:14.192050Z","iopub.status.idle":"2022-12-23T14:09:14.201899Z","shell.execute_reply":"2022-12-23T14:09:14.200714Z","shell.execute_reply.started":"2022-12-23T14:09:14.192382Z"},"id":"O3CyHQ3YTLUp","trusted":true},"outputs":[],"source":["code='''import os\n","\n","# Trainer: Where the âœ¨ï¸ happens.\n","# TrainingArgs: Defines the set of arguments of the Trainer.\n","from trainer import Trainer, TrainerArgs\n","\n","# GlowTTSConfig: all model related values for training, validating and testing.\n","from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n","\n","# BaseDatasetConfig: defines name, formatter and path of the dataset.\n","from TTS.tts.configs.shared_configs import BaseDatasetConfig , CharactersConfig\n","from TTS.config.shared_configs import BaseAudioConfig\n","from TTS.tts.datasets import load_tts_samples\n","from TTS.tts.models.glow_tts import GlowTTS\n","from TTS.tts.utils.text.tokenizer import TTSTokenizer\n","from TTS.utils.audio import AudioProcessor\n","\n","# we use the same path as this script as our training folder.\n","output_path = os.path.dirname(os.path.abspath(__file__))\n","\n","# DEFINE DATASET CONFIG\n","# Set LJSpeech as our target dataset and define its path.\n","# You can also use a simple Dict to define the dataset and pass it to your custom formatter.\n","\n","\n","dataset_config = BaseDatasetConfig(\n","    formatter=\"mozilla\", meta_file_train=\"metadata.csv\", path=\"/kaggle/input/persian-tts-dataset-famale\" \n",")\n","\n","audio_config = BaseAudioConfig(\n","    sample_rate=24000,\n","    do_trim_silence=True,\n","    resample=False\n","    \n",")\n","\n","character_config=CharactersConfig(\n","  characters='Ø¡Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ù„Ù…Ù†Ù‡ÙˆÙŠÙÙ¾Ú†Ú˜Ú©Ú¯ÛŒØ¢Ø£Ø¤Ø¥Ø¦Ù‹ÙÙÙ‘',\n","  punctuations='!(),-.:;? Ì ØŒØ›ØŸâ€Œ<>',\n","  phonemes='ËˆËŒËË‘pbtdÊˆÉ–cÉŸkÉ¡qÉ¢Ê”É´Å‹É²É³nÉ±mÊ™rÊ€â±±É¾É½É¸Î²fvÎ¸Ã°szÊƒÊ’Ê‚ÊÃ§ÊxÉ£Ï‡ÊÄ§Ê•hÉ¦É¬É®Ê‹É¹É»jÉ°lÉ­ÊÊŸaegiouwy',\n","  pad=\"<PAD>\",\n","  eos=\"<EOS>\",\n","  bos=\"<BOS>\",\n","  blank=\"<BLNK>\",\n","  characters_class=\"TTS.tts.utils.text.characters.IPAPhonemes\",\n","  )\n","# INITIALIZE THE TRAINING CONFIGURATION\n","# Configure the model. Every config class inherits the BaseTTSConfig.\n","config = GlowTTSConfig(\n","    batch_size=8,#batch_size=32,\n","    eval_batch_size=4,#eval_batch_size=16,\n","    num_loader_workers=0,\n","    num_eval_loader_workers=0,\n","    run_eval=True,\n","    test_delay_epochs=-1,\n","    epochs=1000,\n","    save_step=1000,\n","    text_cleaner=\"basic_cleaners\",\n","    use_phonemes=True,\n","    phoneme_language=\"fa\",\n","    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n","    characters=character_config,\n","    print_step=25,\n","    print_eval=False,\n","    mixed_precision=True,\n","    output_path=output_path,\n","    datasets=[dataset_config],\n","    audio=audio_config,\n","    test_sentences=[\n","        \"Ø³Ù„Ø·Ø§Ù† Ù…Ø­Ù…ÙˆØ¯ Ø¯Ø± Ø²Ù…Ø³ØªØ§Ù†ÛŒ Ø³Ø®Øª Ø¨Ù‡ Ø·Ù„Ø®Ú© Ú¯ÙØª Ú©Ù‡: Ø¨Ø§ Ø§ÛŒÙ† Ø¬Ø§Ù…Ù‡ ÛŒ ÛŒÚ© Ù„Ø§ Ø¯Ø± Ø§ÛŒÙ† Ø³Ø±Ù…Ø§ Ú†Ù‡ Ù…ÛŒ Ú©Ù†ÛŒ \",\n","        \"Ù…Ø±Ø¯ÛŒ Ù†Ø²Ø¯ Ø¨Ù‚Ø§Ù„ÛŒ Ø¢Ù…Ø¯ Ùˆ Ú¯ÙØª Ù¾ÛŒØ§Ø² Ù‡Ù… Ø¯Ù‡ ØªØ§ Ø¯Ù‡Ø§Ù† Ø¨Ø¯Ø§Ù† Ø®Ùˆ Ø´Ø¨ÙˆÛŒ Ø³Ø§Ø²Ù….\",\n","        \"Ø§Ø² Ù…Ø§Ù„ Ø®ÙˆØ¯ Ù¾Ø§Ø±Ù‡ Ø§ÛŒ Ú¯ÙˆØ´Øª Ø¨Ø³ØªØ§Ù† Ùˆ Ø²ÛŒØ±Ù‡ Ø¨Ø§ÛŒÛŒ Ù…Ø¹Ø·Ù‘Ø± Ø¨Ø³Ø§Ø²\",\n","        \"ÛŒÚ© Ø¨Ø§Ø± Ù‡Ù… Ø§Ø² Ø¬Ù‡Ù†Ù… Ø¨Ú¯ÙˆÛŒÛŒØ¯.\",\n","        \"ÛŒÚ©ÛŒ Ø§Ø³Ø¨ÛŒ Ø¨Ù‡ Ø¹Ø§Ø±ÛŒØª Ø®ÙˆØ§Ø³Øª\"\n","    ],\n","\n","    \n",")\n","\n","# INITIALIZE THE AUDIO PROCESSOR\n","# Audio processor is used for feature extraction and audio I/O.\n","# It mainly serves to the dataloader and the training loggers.\n","ap = AudioProcessor.init_from_config(config)\n","\n","# INITIALIZE THE TOKENIZER\n","# Tokenizer is used to convert text to sequences of token IDs.\n","# If characters are not defined in the config, default characters are passed to the config\n","tokenizer, config = TTSTokenizer.init_from_config(config)\n","\n","# LOAD DATA SAMPLES\n","# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n","# You can define your custom sample loader returning the list of samples.\n","# Or define your custom formatter and pass it to the `load_tts_samples`.\n","# Check `TTS.tts.datasets.load_tts_samples` for more details.\n","train_samples, eval_samples = load_tts_samples(\n","    dataset_config,\n","    eval_split=True,\n","    eval_split_max_size=config.eval_split_max_size,\n","    eval_split_size=config.eval_split_size,\n",")\n","\n","# INITIALIZE THE MODEL\n","# Models take a config object and a speaker manager as input\n","# Config defines the details of the model like the number of layers, the size of the embedding, etc.\n","# Speaker manager is used by multi-speaker models.\n","model = GlowTTS(config, ap, tokenizer, speaker_manager=None)\n","\n","# INITIALIZE THE TRAINER\n","# Trainer provides a generic API to train all the ğŸ¸TTS models with all its perks like mixed-precision training,\n","# distributed training, etc.\n","trainer = Trainer(\n","    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",")\n","\n","# AND... 3,2,1... ğŸš€\n","trainer.fit()\n","'''\n","f=open(\"train_output/train_glowtts.py\",\"w\",encoding=\"utf-8\")\n","\n","f.write(code)\n","\n","f.close()"]},{"cell_type":"markdown","metadata":{"id":"HiVwNfXHYEgD"},"source":["# Start training"]},{"cell_type":"markdown","metadata":{},"source":["For training on first time run this cell: "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:512\" python train_output/train_glowtts.py"]},{"cell_type":"markdown","metadata":{},"source":["to continue training run this cell: \n","- set your own `continue_path`"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:512\" python train_output/train_glowtts.py --continue_path 'train_output/run-December-23-2022_02+09PM-0000000'"]},{"cell_type":"markdown","metadata":{},"source":["# finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mkdir train_output/my_model"]},{"cell_type":"markdown","metadata":{},"source":["Download my last pretrained checkpoint and `config.json` :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget \"https://huggingface.co/Kamtera/persian-tts-female-glow_tts/resolve/main/best_model.pth\" -O \"train_output/my_model/best_model.pth\"\n","!wget \"https://huggingface.co/Kamtera/persian-tts-female-glow_tts/resolve/main/config.json\" -O \"train_output/my_model/config.json\""]},{"cell_type":"markdown","metadata":{},"source":["You could use default settings in `config.json` or edit it with your own parameters.\n","\n","Also , you can set parameters from  cli args like this:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python train_output/train_glowtts.py \\\n","--restore_path \"train_output/my_model/best_model.pth\" \\\n","--coqpit.run_name \"glow-tts-finetune\" \\\n","--coqpit.lr 0.00001"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":4}
